{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "keras.utils.set_random_seed(253)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINNSolver():\n",
    "    def __init__(self, model, alpha, beta, X_r):\n",
    "        self.model = model\n",
    "        self.t = X_r\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "\n",
    "    def get_r(self):\n",
    "        \n",
    "        t = tf.convert_to_tensor(self.t, dtype='float32')\n",
    "        \n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "\n",
    "            tape.watch(t)\n",
    "            u = self.model(t)\n",
    "            u_t = tape.gradient(u, t)\n",
    "\n",
    "            u_tt = tape.gradient(u_t, t)\n",
    "        \n",
    "        del tape\n",
    "\n",
    "        return(u_tt + (self.alpha * u_t) + (self.beta * u))\n",
    "    \n",
    "\n",
    "    # t is inputs\n",
    "    # u is actual outputs\n",
    "    def loss_fn(self, t, u):\n",
    "\n",
    "        r = self.get_r()\n",
    "        phi_r = tf.reduce_mean(tf.square(r))\n",
    "        \n",
    "        loss = phi_r\n",
    "\n",
    "        t_tensor = tf.convert_to_tensor(t, dtype='float32')\n",
    "        u_pred = self.model(t_tensor)\n",
    "        loss += tf.reduce_mean(tf.square(u - u_pred))\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "\n",
    "    def get_grad(self, t, u):\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            tape.watch(self.model.trainable_variables)\n",
    "            loss = self.loss_fn(t, u)\n",
    "\n",
    "        g = tape.gradient(loss, self.model.trainable_variables)\n",
    "        del tape\n",
    "\n",
    "        return loss, g\n",
    "    \n",
    "    def solve_with_TFoptimizer(self, optimizer: keras.optimizers.Optimizer, t, u, epochs):\n",
    "        \n",
    "        def train_step():\n",
    "            loss, gradient = self.get_grad(t, u)\n",
    "            optimizer.apply_gradients(zip(gradient, self.model.trainable_variables))\n",
    "            return loss\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            loss = train_step()\n",
    "            print(\"Epoch: \" + str(i))\n",
    "            print(\"Loss: \" + str(loss))\n",
    "            print(\"Alpha: \" + str(self.alpha))\n",
    "            print(\"Beta: \" + str(self.beta))\n",
    "            print(\"\\n\")\n",
    "            # save every epoch so i can jump ship at any time and still have a network to show for it\n",
    "            self.model.save_weights(\"alpha_beta_problem.weights2.h5\")\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yajuns_function(t: np.float32):\n",
    "    return(-1 * np.power(np.e, t)) + np.power(np.e, 2*t) \n",
    "\n",
    "# lowercase x is x variable, Uppercase is x and t variables combined\n",
    "# *_0 is initial data\n",
    "# *_b is boundary data\n",
    "# *_r is collocation points\n",
    "# *_data is initial data, boundary data\n",
    "# *_d is distributed exact solutions\n",
    "# *_param is _data + _d\n",
    "\n",
    "\n",
    "t_data = np.arange(0, 5, .01, dtype='float32')\n",
    "u_data = np.array([yajuns_function(t) for t in t_data], dtype='float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make layers of the model\n",
    "# most accurate 2 period wave is\n",
    "# 20, 15, 10, 5 with .5 dropout in between\n",
    "\n",
    "def make_network() -> tuple:\n",
    "    layers = []         \n",
    "\n",
    "    layers.append(keras.layers.Dense(20, activation = 'elu', input_shape = (1,)))\n",
    "    layers.append(keras.layers.Dense(20, activation = 'elu'))\n",
    "    layers.append(keras.layers.Dense(20, activation = 'elu'))\n",
    "    layers.append(keras.layers.Dense(20, activation = 'elu'))\n",
    "    layers.append(keras.layers.Dense(20, activation = 'elu'))\n",
    "    layers.append(keras.layers.Dense(20, activation = 'elu'))\n",
    "    layers.append(keras.layers.Dense(20, activation = 'elu'))\n",
    "    layers.append(keras.layers.Dense(20, activation = 'elu'))\n",
    "    output_layer = keras.layers.Dense(1, activation = 'linear')\n",
    "    layers.append(output_layer)\n",
    "    \n",
    "    output_layer.add_weight(shape = (), dtype='float32', trainable=True, name = 'alpha')\n",
    "    output_layer.add_weight(shape = (), dtype='float32', trainable=True, name = 'beta')\n",
    "    \n",
    "    network = keras.Sequential(layers)\n",
    "\n",
    "    # print(output_layer.trainable_weights)\n",
    "\n",
    "    return network, output_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "network, output_layer = make_network()\n",
    "alpha = output_layer.trainable_weights[0]\n",
    "beta = output_layer.trainable_weights[1]\n",
    "\n",
    "solver = PINNSolver(network, alpha, beta, t_data)\n",
    "solver.solve_with_TFoptimizer(keras.optimizers.Adam(), t_data, u_data, 5000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network, output_layer = make_network()\n",
    "network.load_weights(\"alpha_beta_problem.weights2.h5\")\n",
    "x = np.arange(0, 1, .01, dtype='float32')\n",
    "prediction = network.predict(x, verbose = 0)\n",
    "\n",
    "y = np.squeeze(prediction)\n",
    "# y = list(map(lambda a: a*10,y)) # magnification :(\n",
    "\n",
    "plt.plot(t_data, u_data) # blue line, actual sine wave\n",
    "plt.plot(x, y, \"r--\") # red dashes, neural net prediction\n",
    "plt.axis((0, 7, -1, 10000))\n",
    "plt.show()\n",
    "\n",
    "print(u_data)\n",
    "print(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
